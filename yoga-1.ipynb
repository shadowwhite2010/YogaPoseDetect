{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "audioFiles/15sec.wav exists\n",
      "audioFiles/30sec.wav exists\n",
      "audioFiles/45sec.wav exists\n",
      "audioFiles/60sec.wav exists\n",
      "audioFiles/75sec.wav exists\n",
      "audioFiles/90sec.wav exists\n",
      "audioFiles/105sec.wav exists\n",
      "audioFiles/120sec.wav exists\n",
      "audioFiles/135sec.wav exists\n",
      "audioFiles/150sec.wav exists\n",
      "audioFiles/165sec.wav exists\n",
      "audioFiles/180sec.wav exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import threading\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from typing import Mapping\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "from audSample import *\n",
    "from createAudio import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.0.1 in c:\\users\\prathmesh waghmode\\envs\\django-ml\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\prathmesh waghmode\\envs\\django-ml\\lib\\site-packages (from scikit-learn==1.0.1) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\prathmesh waghmode\\envs\\django-ml\\lib\\site-packages (from scikit-learn==1.0.1) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\prathmesh waghmode\\envs\\django-ml\\lib\\site-packages (from scikit-learn==1.0.1) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prathmesh waghmode\\envs\\django-ml\\lib\\site-packages (from scikit-learn==1.0.1) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Prathmesh Waghmode\\Envs\\django-ml\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pickle.load(open('save_model3.unknown', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate angle in three points\n",
    "def getAngles(item, pt1, pt2, pt3):\n",
    "    a = item[pt1]\n",
    "    b = item[pt2]\n",
    "    c = item[pt3]\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = (np.arccos(cosine_angle))*(180/np.pi)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk_vis(lis):\n",
    "    cnt = 0\n",
    "    for obj in lis:\n",
    "        if (obj.visibility>0.5): cnt+=1\n",
    "    if (cnt==33): return True\n",
    "    else: return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "PosesAudioLoc = \"audioFiles/poses/\"\n",
    "SecAudioLoc = \"audioFiles/seconds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recently = []\n",
    "steady_time = []\n",
    "\n",
    "def start_vid(frame_rate):\n",
    "    secCheck = 0\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    # frame_rate = 30\n",
    "    prev = time.time()\n",
    "    threadChk = 0\n",
    "    while(True):\n",
    "        \n",
    "        # Capture the video frame\n",
    "        # by frame\n",
    "        time_elapsed = time.time() - prev\n",
    "        c_time = datetime.datetime.now().strftime('%M')\n",
    "        ret, frame = vid.read()\n",
    "        # time_elapsed = time.time() - prev\n",
    "        # ret, frame = self.video.read()\n",
    "        if time_elapsed > 1./frame_rate:\n",
    "            prev = time.time()\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            with mp_pose.Pose() as pose_tracker:\n",
    "                result = pose_tracker.process(image=frame)\n",
    "                # mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                pose_landmarks = result.pose_landmarks\n",
    "            output_frame = frame.copy()\n",
    "            dict_obj = {}\n",
    "            for i in range(0,33):\n",
    "                \n",
    "                dict_obj[i] = mp_drawing.DrawingSpec(color=mp_drawing.BLUE_COLOR)\n",
    "            dict_obj[13] = mp_drawing.DrawingSpec(color=(0, 128, 0))\n",
    "            dict_obj[15] = mp_drawing.DrawingSpec(color=(0, 128, 0))\n",
    "            dict_obj[11] = mp_drawing.DrawingSpec(color=(0, 128, 0)) \n",
    "            x: Mapping[int, mp_drawing.DrawingSpec] = dict_obj\n",
    "            # print(pose_landmarks.landmark)\n",
    "            pose_name = \"\"\n",
    "            if pose_landmarks is not None:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=output_frame,\n",
    "                    landmark_list=pose_landmarks,\n",
    "                    connections=mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=  x)\n",
    "                assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "                if chk_vis(pose_landmarks.landmark): \n",
    "                    pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "                    # output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                    frame_height, frame_width = frame.shape[:2]\n",
    "                    pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "                    # uncomment this when predicting\n",
    "                    item = pose_landmarks\n",
    "                    arr = np.array([getAngles(item, 13, 11, 12),\n",
    "                    getAngles(item, 24, 12, 14),\n",
    "                    getAngles(item, 15, 13, 11),\n",
    "                    getAngles(item, 12, 14, 16),\n",
    "                    getAngles(item, 11, 23, 25),\n",
    "                    getAngles(item, 12, 24, 26),\n",
    "                    getAngles(item, 23, 25, 27),\n",
    "                    getAngles(item, 24, 26, 28)])\n",
    "                    res = classifier.predict([arr]) # classified pose name\n",
    "                    pose_name = res[0]\n",
    "                # ####### #\n",
    "            cv2.rectangle(output_frame, (0,0), (650, 50), (0,0,0), -1)\n",
    "            output_frame = cv2.putText(output_frame, pose_name, (25,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # cv2.imshow('frame', output_frame)\n",
    "\n",
    "            c_time = timer()\n",
    "            \n",
    "            if pose_name != \"\":\n",
    "                steady_time_now = timer()\n",
    "                steadyF = 0\n",
    "                if not steady_time:\n",
    "                    steady_time.append(steady_time_now)\n",
    "                elif (steady_time_now - steady_time[0])>3:\n",
    "                    steadyF = 1\n",
    "                else:\n",
    "                    # print(steady_time_now-steady_time[0])\n",
    "                    steady_time.append(steady_time_now)\n",
    "                    \n",
    "                output_frame = cv2.putText(output_frame, str(\"{:.0f}\".format(steady_time_now-steady_time[0]))+\" s\", (300,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                if steadyF == 1:\n",
    "                    countSay = \"{:.0f}\".format(steady_time_now-steady_time[0])\n",
    "                    if not recently: # classify and say\n",
    "                        t1 = threading.Thread(target=start_playlist, args=[[ f\"{PosesAudioLoc}{pose_name}.wav\"]])\n",
    "                        t1.start()\n",
    "                        threadChk = 1\n",
    "                        recently.append(c_time)\n",
    "\n",
    "                    elif secCheck==0:\n",
    "                        if int(countSay)%15 == 0:\n",
    "                            print(countSay)\n",
    "                            # basePerform = \"seconds complete\"\n",
    "                            # textList = [f\"{countSay} {basePerform}\"]\n",
    "                            # createAudio(textList, f\"{audiosLoc}{countSay}sec.wav\")\n",
    "                            t1 = threading.Thread(target=start_playlist, args=[[ f\"{SecAudioLoc}{countSay}sec.wav\"]])\n",
    "                            t1.start()\n",
    "                            recently.pop()\n",
    "                            recently.append(c_time)\n",
    "                            secCheck = 1\n",
    "                        else:\n",
    "                            secCheck = 0\n",
    "                    \n",
    "                    if secCheck==1 and int(countSay)%15 != 0: secCheck=0\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                steady_time.clear()\n",
    "                recently.clear()\n",
    "            cv2.imshow('frame', output_frame)\n",
    "\n",
    "                \n",
    "                    \n",
    "            \n",
    "        \n",
    "        # the 'q' button is set as the\n",
    "        # quitting button you may use any\n",
    "        # desired button of your choice\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    if threadChk: t1.join()\n",
    "    # After the loop release the cap object\n",
    "    vid.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\prathmesh waghmode\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\prathmesh waghmode\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\sem 7\\mini-project\\project\\YogaPoseDetect\\audSample.py\", line 26, in start_playlist\n",
      "    pygame.mixer.music.queue(playList[0])\n",
      "IndexError: list index out of range\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\prathmesh waghmode\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\prathmesh waghmode\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\sem 7\\mini-project\\project\\YogaPoseDetect\\audSample.py\", line 26, in start_playlist\n",
      "    pygame.mixer.music.queue(playList[0])\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "start_vid(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('django-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "545369ce476304470c375f61bead7790a92abb918387bb86e6d16e9b65fc3018"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
